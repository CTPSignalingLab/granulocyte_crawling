{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Версия с обработчиком мгновенных скоростей и траекторий\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "import trackpy as tp \n",
    "import numpy \n",
    "import matplotlib.pylab as plt \n",
    "import matplotlib\n",
    "import pims_nd2\n",
    "import numpy as np\n",
    "from matplotlib.widgets import TextBox\n",
    "import pandas as pd\n",
    "\n",
    "from cv2_rolling_ball import subtract_background_rolling_ball\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Папка, в которой находится файл\n",
    "\n",
    "folder = r'C:\\Users\\Julia\\Downloads'\n",
    "\n",
    "# Имя файла\n",
    "\n",
    "filename = 'ulyana_002'\n",
    "\n",
    "# Номера каналов для обсчёта:\n",
    "    \n",
    "# Если было снято в каналах 405 (Хёкст), 488 (DiOC6, CD61) и 640 (Annexin-V-Alexa647, P-Selectin-Alexa647)\n",
    "# 405 - 0\n",
    "# 488 - 1\n",
    "# 640 - 2\n",
    "\n",
    "# Если было снято в каналах 488 (DiOC6, CD61) и 640 (Annexin-V-Alexa647, P-Selectin-Alexa647)\n",
    "# 488 - 0\n",
    "# 640 - 1\n",
    "\n",
    "channel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveBackground: \n",
    "    def __init__(self, trace, channel_number=0):\n",
    "    #вводим ссылку на файл и номер интересующего канала\n",
    "        self.trace = trace\n",
    "        frames = pims_nd2.ND2_Reader(self.trace)\n",
    "        \n",
    "        self.frames = frames\n",
    "        self.x = self.frames.sizes.get('x')\n",
    "        self.y = frames.sizes.get('y')\n",
    "        self.channel_number = channel_number\n",
    "        self.remove_bg_number = 0\n",
    "        self.c = frames.sizes.get('c')\n",
    "        self.z = frames.sizes.get('m')\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        plt.axis('off')\n",
    "        #делаем массив вместо nd2-файла\n",
    "        \n",
    "        \n",
    "        grid_sz = 15\n",
    "        max \n",
    "        plt.subplot2grid((grid_sz,grid_sz), (0,0), colspan=grid_sz, rowspan=grid_sz-1)\n",
    "        self.img=self.frames[0]\n",
    "        self.zerozero = plt.imshow(self.img)\n",
    "        button_ax = plt.subplot2grid((grid_sz,grid_sz ), (grid_sz-1,grid_sz*3//6))\n",
    "        z_stack_ax = plt.subplot2grid((grid_sz,grid_sz ), (grid_sz-1,grid_sz*1//6))\n",
    "        channel_ax = plt.subplot2grid((grid_sz,grid_sz ), (grid_sz-1,grid_sz*5//6))\n",
    "        channel_error=0\n",
    "        #массив времен, вытащенный из метаданных\n",
    "        self.zerozero.axes.get_xaxis().set_visible(False)\n",
    "        self.zerozero.axes.get_yaxis().set_visible(False)\n",
    "        self.done_button = plt.Button(button_ax, 'Done')\n",
    "        self.done_button.on_clicked(self.on_button_press)\n",
    "        self.ChannelBox = TextBox(channel_ax, 'Rolling ball size')\n",
    "        self.ChannelBox.on_submit(self.on_remove_bg_number_update_process)\n",
    "        self.CellBox = TextBox(z_stack_ax, 'Zstack number')\n",
    "        self.CellBox.on_submit(self.on_z_stack_number_update_process)\n",
    "        plt.show()\n",
    "        self.fig.canvas.start_event_loop(timeout=-1)\n",
    "        \n",
    "    def on_button_press(self, event):\n",
    "            self.pixel_size = self.frames[0].metadata['mpp']\n",
    "            self.frames.close()\n",
    "            self.img = self.img[:]\n",
    "            #print (\"X dimension = \", x, \"Y dimension = \" , y, \"Time length = \", t)\n",
    "\n",
    "            plt.close()\n",
    "            self.fig.canvas.stop_event_loop()\n",
    "            \n",
    "    def on_z_stack_number_update_process(self, val):\n",
    "            try:\n",
    "                self.zstack_number = int(eval(val))\n",
    "                self.frames.default_coords['m'] = self.zstack_number\n",
    "                self.img=self.frames[0]\n",
    "                 \n",
    "                self.zerozero.set_data(self.img)\n",
    "            except:  \n",
    "                print ('Error!')\n",
    "    def on_remove_bg_number_update_process(self, val):\n",
    "            try:\n",
    "                self.remove_bg_number = int(eval(val))\n",
    "                \n",
    "                image_c, background = subtract_background_rolling_ball(np.uint8(self.frames[0]), eval(val), light_background=False,\n",
    "                                                     use_paraboloid=False, do_presmooth=False)\n",
    "                print(np.mean(image_c))\n",
    "                #self.frames.default_coords['c'] = self.channel_number\n",
    "                self.img = image_c\n",
    "                self.zerozero.set_data(self.img)\n",
    "            except Exception as e:  \n",
    "                print ('Error!',e)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "class ImageProcessingGUI():\n",
    "    def __init__(self, img, img_labels, trajectories, dictionary_frames):\n",
    "\n",
    "        self.fig = plt.figure(figsize=(20,15))\n",
    "        self.img = img\n",
    "        self.img_labels = img_labels\n",
    "        grid_sz = 15\n",
    "        self.currentvideoindice = 1\n",
    "        self.dictionary_frames = dictionary_frames\n",
    "        self.currtype = 'not specified'\n",
    "        self.trajectories = trajectories\n",
    "        self.curr_type_label = ''\n",
    "        plt.subplot2grid((grid_sz, grid_sz), (0, 0), colspan=grid_sz, rowspan=grid_sz - 1)\n",
    "\n",
    "        tp.plot_traj(self.trajectories, label=True)\n",
    "        self.zerozero = plt.imshow(self.img[self.currentvideoindice], alpha=0.9)\n",
    "        # self.imgprev = plt.imshow(self.img_labels[self.currentvideoindice], alpha = 0.6, cmap = 'jet')\n",
    "        # plt.plot(trajectories)\n",
    "\n",
    "        z_stack_ax = plt.subplot2grid((grid_sz, grid_sz), (grid_sz - 1, grid_sz * 5 // 6))\n",
    "        z_stack_ax1 = plt.subplot2grid((grid_sz, grid_sz), (grid_sz - 1, grid_sz * 7 // 9))\n",
    "        self.selected_cell_labels = []\n",
    "        self.cell_labels = img_labels\n",
    "        self.cell_mask = None\n",
    "\n",
    "        self.CellBox = TextBox(z_stack_ax, 'Leuco Traj N')\n",
    "        self.CellBoxType = TextBox(z_stack_ax1, 'Leuco Type')\n",
    "        self.CellBox.on_submit(self.on_z_stack_number_update_process)\n",
    "        \n",
    "        self.CellBoxType.on_submit(self.on_type_number_update_process)\n",
    "        self.zerozero.axes.get_xaxis().set_visible(False)\n",
    "        self.zerozero.axes.get_yaxis().set_visible(False)\n",
    "        plt.title('Use sliders to choose current slide')\n",
    "        plt.axis('off')\n",
    "        # self.cid = self.fig.canvas.mpl_connect('button_press_event', self.on_mouse_click)\n",
    "        slider_ax1 = plt.subplot2grid((grid_sz, grid_sz), (grid_sz - 1, grid_sz * 1 // 6))\n",
    "        button_ax = plt.subplot2grid((grid_sz, grid_sz), (grid_sz - 1, grid_sz * 2 // 6))\n",
    "\n",
    "        self.done_button = plt.Button(button_ax, 'Done')\n",
    "        self.done_button.on_clicked(self.on_button_press)\n",
    "        self.cutting = plt.Slider(slider_ax1, 'Current slide', 0, (np.shape(img_labels)[0] - 1),\n",
    "                                  valinit=self.currentvideoindice, valstep=1)\n",
    "        self.cutting.on_changed(self.on_slider_process)\n",
    "        self.enum_particles = 0\n",
    "        plt.show()\n",
    "        self.fig.canvas.start_event_loop(timeout=-1)\n",
    "\n",
    "    def on_button_press(self, event):\n",
    "        plt.close()\n",
    "        self.fig.canvas.stop_event_loop()\n",
    "\n",
    "    def on_slider_process(self, val):\n",
    "        self.currentvideoindice = int(val)\n",
    "        self.zerozero.set_data(self.img[self.currentvideoindice])\n",
    "        self.zerozero.set_norm(matplotlib.colors.Normalize())\n",
    "        self.zerozero.set_cmap('viridis')\n",
    "        \n",
    "        # self.imgprev.set_data(self.img_labels[self.currentvideoindice])\n",
    "        plt.draw()\n",
    "\n",
    "    def on_z_stack_number_update_process(self, val):\n",
    "        try:\n",
    "            self.label = np.array(eval(val),ndmin=1)\n",
    "           \n",
    "            print(self.label)\n",
    "            self.enum_particles+= 1\n",
    "            print({'indices':self.label,'celltype':self.currtype} )\n",
    "            self.CellBox.set_val('')\n",
    "            self.selected_cell_labels.append({'indices':self.label,'celltype':self.currtype} )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Error1!', e)\n",
    "            \n",
    "    def on_type_number_update_process(self, val):\n",
    "        try:\n",
    "            self.currtype =  val\n",
    "            #self.selected_cell_labels.append(self.label)\n",
    "        except Exception as e:\n",
    "            print('Error2!',e)\n",
    "\n",
    "def get_z_size(trace):\n",
    "    frames = pims_nd2.ND2_Reader(trace)\n",
    "    z = frames.sizes.get('m')\n",
    "\n",
    "    pixel_size = frames[0].metadata['mpp']\n",
    "    print(frames.metadata)\n",
    "    frames.close()\n",
    "    return z, pixel_size\n",
    "\n",
    "def GetFilmingInitTime(trace):\n",
    "    \n",
    "    frames = pims_nd2.ND2_Reader(trace)\n",
    "    datetime_init = (frames.metadata['time_start'])\n",
    "    \n",
    "    frames.close()\n",
    "    return datetime_init\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getND2timeframes(z_stack, trace,channel_number=1):\n",
    "    frames = pims_nd2.ND2_Reader(trace)\n",
    "    \n",
    "    if (z_stack):\n",
    "        frames.default_coords['m'] = z_stack\n",
    "    frames.default_coords['c'] = channel_number\n",
    "    # делаем массив вместо nd2-файла\n",
    "    t = frames.sizes.get('t')\n",
    "    times = numpy.zeros((t))\n",
    "    \n",
    "    for i in range(t):\n",
    "        times[i] = frames[i].metadata['t_ms'] / 1000\n",
    "    return times    \n",
    "def getNd2efunc(z_stack, trace,ret_rolling_ball, channel_number=1, max_chunx = None, split_image = None):\n",
    "    frames = pims_nd2.ND2_Reader(trace)\n",
    "    x = frames.sizes.get('x')\n",
    "    y = frames.sizes.get('y')\n",
    "    \n",
    "    if (z_stack):\n",
    "        frames.default_coords['m'] = z_stack\n",
    "    frames.default_coords['c'] = channel_number\n",
    "    # делаем массив вместо nd2-файла\n",
    "    t = frames.sizes.get('t')\n",
    "    times = numpy.zeros((t))\n",
    "    if (split_image!=None):\n",
    "        number = (np.sqrt(max_chunx))+1\n",
    "        one_size_x = int(np.floor(x/number))\n",
    "        nx = int(split_image%number)\n",
    "        ny = int(split_image//number)\n",
    "        one_size_y = int(np.floor(y/number))\n",
    "        print(nx,ny,one_size_x,one_size_y)\n",
    "        \n",
    "        img = numpy.zeros((t, one_size_x, one_size_y))\n",
    "    else:\n",
    "        img = numpy.zeros((t, x, y))\n",
    "    #print(x,y,nx,ny,(nx)*one_size_x,(ny)*one_size_y)    \n",
    "    for i in range(t):\n",
    "        \n",
    "        #frames_subtract, background = subtract_background_rolling_ball(frames[i], ret_rolling_ball, light_background=False,\n",
    "                                     #use_paraboloid=False, do_presmooth=True)\n",
    "        #img[i, :, :] = frames_subtract\n",
    "        if (split_image!=None):\n",
    "            img[i, :, :] = frames[i].T[nx*one_size_x:(nx+1)*one_size_x,ny*one_size_y:(ny+1)*one_size_y]\n",
    "        else:\n",
    "            img[i, :, :] = frames[i].T\n",
    "            \n",
    "        times[i] = frames[i].metadata['t_ms'] / 1000\n",
    "    # размер пикселя, тащимыйВ из метаданных\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    frames_fon = frames[:]\n",
    "    frames.close()\n",
    "    frames = img[:]\n",
    "\n",
    "    frames_fon = frames.copy()\n",
    "    f = tp.batch(frames_fon[:], 91)\n",
    "    t = tp.link_df(f, int(np.floor(15*2.875)), memory=3)\n",
    "    f = tp.filter_stubs(t, 4)\n",
    "    \"\"\"\n",
    "        img = img[:10]\n",
    "        times = times[:10]\"\"\"\n",
    "    dictionary = {}\n",
    "\n",
    "    for i in (f['particle']):\n",
    "        particle_center_list = []\n",
    "        key = (f[f['particle'] == i])\n",
    "        frame_list_for_particles = (f[f['particle'] == i])['frame']\n",
    "\n",
    "        for j in frame_list_for_particles:\n",
    "            centurx1 = key[key['frame'] == j]\n",
    "            centurx = np.float64(centurx1['x'])\n",
    "            century = np.float64(centurx1['y'])\n",
    "            size = np.float64(centurx1['size'])\n",
    "            particle_center_list.append([j, centurx, century, size])\n",
    "\n",
    "        dictionary[i] = particle_center_list\n",
    "    frame_labels = np.zeros_like(frames)\n",
    "    # print (dictionary)\n",
    "\n",
    "    binarize_video = np.zeros_like(frames_fon)\n",
    "\n",
    "    for i in range(np.shape(binarize_video)[0]):\n",
    "        ret, binarize_video[i] = cv2.threshold(np.uint8(frames_fon[i] * 255 / np.max(frames_fon[i])), 0, 255,\n",
    "                                               cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    if (split_image!=None):    \n",
    "        return binarize_video, frames_fon, frame_labels, f, dictionary, times, split_image\n",
    "    else:\n",
    "        return binarize_video, frames_fon, frame_labels, f, dictionary, times, z_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pims\\base_frames.py:522: UserWarning: Please call FramesSequenceND.__init__() at the start of thethe reader initialization.\n",
      "  warn(\"Please call FramesSequenceND.__init__() at the start of the\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'width': 512, 'width_bytes': 2048, 'height': 512, 'components': 2, 'bitsize_memory': 16, 'bitsize_significant': 14, 'sequence_count': 760, 'tile_width': 512, 'tile_height': 512, 'compression': None, 'compression_quality': 4294967197, 'plane_count': 2, 'angle': 0.0, 'calibration_um': 0.159555420061708, 'time_start_jdn': 2458792.117578947, 'time_start': datetime.datetime(2019, 11, 4, 17, 49, 18, 821020), 'time_start_utc': datetime.datetime(2019, 11, 4, 14, 49, 18, 821020), 'objective': 'Apo TIRF 100x Oil DIC N2', 'magnification': -1.0, 'NA': 1.49, 'refractive_index1': 1.515, 'refractive_index2': 1.515, 'pinhole': 0.0, 'zoom': 1.0, 'projective_mag': -1.0, 'image_type': 'normal', 'z_home': None, 'plane_0': {'components': 1, 'rgb_value': (0.0, 0.9568627450980393, 1.0), 'name': '488 nm', 'oc': 'Stacey_flow', 'emission_nm': 488.0}, 'plane_1': {'components': 1, 'rgb_value': (1.0, 0.0, 0.0), 'name': '640 nm', 'oc': 'Stacey_flow', 'emission_nm': 640.0}}\n"
     ]
    }
   ],
   "source": [
    "ret_rolling_ball = 300\n",
    "\n",
    "from cv2_rolling_ball import subtract_background_rolling_ball\n",
    "\n",
    "TRACE = folder + '/' + filename\n",
    "z_max, mpp = get_z_size(TRACE + '.nd2')\n",
    "\n",
    "bg = RemoveBackground(TRACE + '.nd2')\n",
    "ret_rolling_ball  = bg.remove_bg_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "max_chunks = 9\n",
    "array_of_results = np.zeros(z_max)\n",
    "#ret_rolling_ball = 0\n",
    "# [frames, times, mpp] = getNd2efunc(trace=TRACE+'.nd2', channel_number = 1, zstack = z_max)\n",
    "\n",
    "#getNd2efunc(0, TRACE + '.nd2', ret_rolling_ball, channel,max_chunks, 1)\n",
    "if (z_max):\n",
    "    all_z_stack_results = (Parallel(n_jobs=-1)(delayed(getNd2efunc)(i, TRACE + '.nd2', ret_rolling_ball, channel) for i in range(z_max)))\n",
    "else:\n",
    "    all_z_stack_results = (Parallel(n_jobs=-1)(delayed(getNd2efunc)(0, TRACE + '.nd2', ret_rolling_ball, channel,max_chunks, i) for i in range(max_chunks)))\n",
    "zstack_num = z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "{'indices': array([6]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[2]\n",
      "{'indices': array([2]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([6]), 'celltype': 'not specified'}, {'indices': array([2]), 'celltype': 'not specified'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.337615966796875 \t 10.486602783203125\n",
      "[]\n",
      "8.946990966796875 \t 9.383773803710938\n",
      "[13]\n",
      "{'indices': array([13]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([13]), 'celltype': 'not specified'}]\n",
      "10.6414794921875 \t 10.388565063476562\n",
      "[6]\n",
      "{'indices': array([6]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[14]\n",
      "{'indices': array([14]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([6]), 'celltype': 'not specified'}, {'indices': array([14]), 'celltype': 'not specified'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.155059814453125 \t 9.90447998046875\n",
      "[4]\n",
      "{'indices': array([4]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([4]), 'celltype': 'not specified'}]\n",
      "7.433319091796875 \t 6.4891815185546875\n",
      "[19]\n",
      "{'indices': array([19]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[21]\n",
      "{'indices': array([21]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([19]), 'celltype': 'not specified'}, {'indices': array([21]), 'celltype': 'not specified'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.999679565429688 \t 14.172744750976562\n",
      "[2]\n",
      "{'indices': array([2]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[4]\n",
      "{'indices': array([4]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[0]\n",
      "{'indices': array([0]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([2]), 'celltype': 'not specified'}, {'indices': array([4]), 'celltype': 'not specified'}, {'indices': array([0]), 'celltype': 'not specified'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ar = np.asanyarray(ar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.932876586914062 \t 8.571624755859375\n",
      "[3]\n",
      "{'indices': array([3]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([3]), 'celltype': 'not specified'}]\n",
      "9.889984130859375 \t 9.235000610351562\n",
      "[18]\n",
      "{'indices': array([18]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([18]), 'celltype': 'not specified'}]\n",
      "9.132003784179688 \t 12.044525146484375\n",
      "[5]\n",
      "{'indices': array([5]), 'celltype': 'not specified'}\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "Error1! unexpected EOF while parsing (<string>, line 0)\n",
      "[{'indices': array([5]), 'celltype': 'not specified'}]\n",
      "11.3494873046875 \t 13.818359375\n"
     ]
    }
   ],
   "source": [
    "for all_elems in all_z_stack_results:\n",
    "    all_coords_array_t = []\n",
    "    all_coords_array_x = []\n",
    "    all_coords_array_y = []\n",
    "    all_coords_array_names = []\n",
    "    percent = []\n",
    "    binarize_video, frames_fon, frame_labels, f, dictionary, times, zstack_current_num = all_elems\n",
    "    gui = ImageProcessingGUI(frames_fon, frame_labels, f, dictionary)\n",
    "    label_list = gui.selected_cell_labels\n",
    "    \n",
    "    all_velocities_array = []\n",
    "    print(gui.selected_cell_labels)\n",
    "    for all_neutrophils in gui.selected_cell_labels:\n",
    "        velocity_array = []\n",
    "        x_array = []\n",
    "        y_array = []\n",
    "        t_array = []\n",
    "        name_array = []\n",
    "        for j in (all_neutrophils['indices']):\n",
    "            #j = int(re.sub(\"[^0-9]\", \"\", j))\n",
    "            #velocities = np.zeros(len(dictionary[j]))\n",
    "            for frame_enum in range(1, len(dictionary[j])):\n",
    "                frame_nr = dictionary[j][frame_enum][0]\n",
    "                delta_t = times[frame_nr] - times[dictionary[j][frame_enum - 1][0]]\n",
    "                delta_x = dictionary[j][frame_enum][1] - dictionary[j][frame_enum - 1][1]\n",
    "                delta_y = dictionary[j][frame_enum][2] - dictionary[j][frame_enum - 1][2]\n",
    "    \n",
    "                velocity = np.sqrt(delta_x ** 2 + delta_y ** 2)\n",
    "                velocity = velocity * mpp / delta_t\n",
    "                velocity_array.append(velocity)\n",
    "                t_array.append(times[frame_nr])\n",
    "                x_array.append(dictionary[j][frame_enum][1])\n",
    "                y_array.append(dictionary[j][frame_enum][2])\n",
    "                mask = np.zeros_like(binarize_video[frame_nr])\n",
    "                size_leuco = dictionary[j][frame_enum][3]\n",
    "                x_this_slide = dictionary[j][frame_enum][1]\n",
    "                y_this_slide = dictionary[j][frame_enum][2]\n",
    "                mask[int(y_this_slide - size_leuco * 1.2):int(y_this_slide + size_leuco * 1.2),\n",
    "                int(x_this_slide - size_leuco * 1.2):int(x_this_slide + size_leuco * 1.2)] += 1\n",
    "                binarize_video[frame_nr][mask == 1] *= 0\n",
    "                name_array.append(all_neutrophils['celltype'])\n",
    "        all_velocities_array.append(velocity_array)\n",
    "        all_coords_array_t.append(t_array)\n",
    "        all_coords_array_x.append(x_array)\n",
    "        all_coords_array_y.append(y_array)\n",
    "        all_coords_array_names.append(name_array)\n",
    "\n",
    "    for j in range(np.shape(binarize_video)[0]):\n",
    "            frame_thrombus_per_cent = len(binarize_video[j][binarize_video[j] != 0]) / (\n",
    "                        np.shape(binarize_video)[2] * np.shape(binarize_video)[1])\n",
    "            percent.append(frame_thrombus_per_cent)\n",
    "    fig = plt.figure() \n",
    "    \n",
    "    time = times.tolist()\n",
    "    first = time.index(min(time, key=lambda x: abs(x - 300)))\n",
    "    fig.suptitle('300 second clot, field #'+str(zstack_current_num+1))\n",
    "    plt.imshow(frames_fon[first])        \n",
    "    #plt.imshow(binarize_video[first], alpha = 0.3)\n",
    "    #plt.show()\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('600 second clot, field #'+str(zstack_current_num+1))\n",
    "    plt.imshow(frames_fon[-1]) \n",
    "    #plt.imshow(binarize_video[-1], alpha = 0.3)\n",
    "    #plt.show()\n",
    "\n",
    "    import xlwt\n",
    "\n",
    "    ex = xlwt.Workbook()\n",
    "    vel = ex.add_sheet('Velocity', cell_overwrite_ok=True)\n",
    "    thrombus = ex.add_sheet('Clot', cell_overwrite_ok=True)\n",
    "    Mean_vals = ex.add_sheet('Mean values', cell_overwrite_ok=True)\n",
    "    coords = ex.add_sheet('Coords', cell_overwrite_ok=True)\n",
    "    num = 0\n",
    "    for different_velocities in (all_velocities_array):\n",
    "        num += 1\n",
    "        Mean_vals.write(1,2 * num+4, np.mean(different_velocities))\n",
    "        Mean_vals.write(0,2*num+4,\"Mean Velocity №\"+str(num))\n",
    "        vel.write(0,2*num + 0, 'Velocity №'+str(num))\n",
    "        for i in range(len(different_velocities)):\n",
    "            vel.write(i+1, 2*num + 0, different_velocities[i])\n",
    "    num = 0        \n",
    "    for different_coords in (all_coords_array_x):\n",
    "        num += 1\n",
    "        coords.write(0,4 * num + 0, 'Coords X №'+str(num))\n",
    "        for i in range(len(different_coords)):\n",
    "            coords.write(i+1, 4 * num + 0, different_coords[i])\n",
    "    num = 0        \n",
    "    for different_coords_y in (all_coords_array_y):\n",
    "        num += 1\n",
    "        coords.write(0,4 * num + 1, 'Coords Y №'+str(num))\n",
    "        for i in range(len(different_coords_y)):\n",
    "            coords.write(i+1, 4 * num + 1, different_coords_y[i])\n",
    "    num = 0        \n",
    "    for different_coords_t in (all_coords_array_t):\n",
    "        num += 1\n",
    "        coords.write(0,4 * num +2, 'T №'+str(num))\n",
    "        for i in range(len(different_coords_t)):\n",
    "            coords.write(i+1, 4 * num +2, different_coords_t[i])\n",
    "    num = 0        \n",
    "    for different_names in (all_coords_array_names):\n",
    "        num += 1\n",
    "        coords.write(0,4 * num +3,  'Type №'+str(num))\n",
    "        vel.write(0,2 * num +1,  'Type №'+str(num))\n",
    "        Mean_vals.write(0,2 * num+5, 'Type №'+str(num))\n",
    "        Mean_vals.write(1,2 * num+5, different_names[1])\n",
    "        for i in range(len(different_names)):\n",
    "            \n",
    "            coords.write(i+1, 4 * num + 3, different_names[i])\n",
    "            vel.write(i+1, 2 * num + 1, different_names[i])\n",
    "    all_names_for_means = np.unique(all_coords_array_names)          \n",
    "    num = 0  \n",
    "    thrombus.write(0, 2, 'Clot square')\n",
    "    thrombus.write(0, 0, 'Time')\n",
    "    for j in range(len(percent)):\n",
    "        thrombus.write(j+1, 2, percent[j])\n",
    "        thrombus.write(j+1, 0, time[j])\n",
    "\n",
    "    first = time.index(min(time, key=lambda x: abs(x - 300)))\n",
    "    print(percent[first] * 100, '\\t', percent[-1] * 100)\n",
    "    Mean_vals.write(1, 0, '300s')\n",
    "    Mean_vals.write(1, 1, '600s')\n",
    "    Mean_vals.write(0, 3, 'Mean velocities')\n",
    "    Mean_vals.write(2, 0, percent[first])\n",
    "    Mean_vals.write(2, 1, percent[-1])\n",
    "\n",
    "    ex.save(TRACE + '_field' + str(zstack_current_num + 1) + '.xls')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not specified', 'not specified']\n",
      "['not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified', 'not specified']\n",
      "['all_names' 'not specified']\n",
      "Traj [137.84936972236892, 52.61743479636207, 72.85358320911037, 167.14216976005437, 36.057042498475134, 148.45395149979112, 47.09214610615017, 72.21948068747021, 26.771267355047875, 51.95020875425213, 49.67441871909636, 54.74939925072228, 202.27332589330075, 254.72883586152815]\n",
      "Traj [137.84936972236892, 52.61743479636207, 72.85358320911037, 167.14216976005437, 36.057042498475134, 148.45395149979112, 47.09214610615017, 72.21948068747021, 26.771267355047875, 51.95020875425213, 49.67441871909636, 54.74939925072228, 202.27332589330075, 254.72883586152815]\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.1851400231474151\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "0.014728258986968674\n",
      "Type №1\n",
      "not specified\n",
      "Mean Velocity №2\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1851400231474151\n",
      "not specified\n",
      "0.014728258986968674\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.04389009026488538\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.04389009026488538\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.04721906009084497\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "0.06888652105546739\n",
      "Type №1\n",
      "not specified\n",
      "Mean Velocity №2\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.04721906009084497\n",
      "not specified\n",
      "0.06888652105546739\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.040614075668134623\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.040614075668134623\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.19980183060775455\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "0.037532294808345266\n",
      "Type №1\n",
      "not specified\n",
      "Mean Velocity №2\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.19980183060775455\n",
      "not specified\n",
      "0.037532294808345266\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.05400928135486884\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "0.04621865907975032\n",
      "Type №1\n",
      "not specified\n",
      "Mean Velocity №2\n",
      "0.0641428775236495\n",
      "Type №2\n",
      "not specified\n",
      "Mean Velocity №3\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.05400928135486884\n",
      "not specified\n",
      "0.04621865907975032\n",
      "not specified\n",
      "0.0641428775236495\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.03352201148752385\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.03352201148752385\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.08716753790422704\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.08716753790422704\n",
      "not specified\n",
      "600s\n",
      "Unnamed: 0\n",
      "nan\n",
      "Unnamed: 1\n",
      "nan\n",
      "Unnamed: 2\n",
      "nan\n",
      "Mean velocities\n",
      "nan\n",
      "Unnamed: 4\n",
      "0.1677695055203274\n",
      "Unnamed: 5\n",
      "not specified\n",
      "Mean Velocity №1\n",
      "600s\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1677695055203274\n",
      "not specified\n"
     ]
    }
   ],
   "source": [
    "# Окошко, которое генерирует файл с отдельными данными\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)',text)]\n",
    "\n",
    "def get_files(path, file, printnames = False):\n",
    "\n",
    "    listOfFiles = os.listdir(path)\n",
    "    pattern = file + '_field*'\n",
    "    \n",
    "    i = 0\n",
    "    filenames = []\n",
    "    for entry in listOfFiles:\n",
    "        if fnmatch.fnmatch(entry, pattern):\n",
    "            filenames.append(entry)\n",
    "            \n",
    "    filenames.sort(key = natural_keys)\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def get_files_ND2(path, printnames = False):\n",
    "\n",
    "    listOfFiles = os.listdir(path)\n",
    "    filenames = []\n",
    "    for entry in listOfFiles:\n",
    "        if entry.endswith('nd2'):\n",
    "            filenames.append(entry)\n",
    "            \n",
    "    filenames.sort(key = natural_keys)\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "\n",
    "def all_names(folder, type, N_patients):\n",
    "    for i in range(N_patients):\n",
    "        Leuko_names = []\n",
    "        path_tmp = folder + '/' + type\n",
    "        entry_list = get_files(folder, type)\n",
    "        for j in range(len(entry_list)):\n",
    "            data_names = pd.read_excel(folder + '/' + entry_list[j],\n",
    "                                      sheet_name='Mean values')\n",
    "            #print(data_names.columns)\n",
    "            headers = list(data_names.columns)\n",
    "            \n",
    "            for k in range(len(headers)):\n",
    "                if 'Type №' in headers[k]:\n",
    "                    Leuko_names.append(data_names[headers[k]][0])\n",
    "            print(Leuko_names)     \n",
    "        Leuko_names.append('all_names')   \n",
    "        return np.unique(Leuko_names)        \n",
    "            \n",
    "\n",
    "def traj(folder, type, N_patients, name_curr):\n",
    "    for i in range(N_patients):\n",
    "        instant_velocities = []\n",
    "        path_tmp = folder + '/' + type\n",
    "\n",
    "#         path_tmp = folder + '/' + str(i + 1) + 'D' + '/' + type\n",
    "        entry_list = get_files(folder, type)\n",
    "#         print(entry_list)\n",
    "        traj_lens = []\n",
    "        for j in range(len(entry_list)):\n",
    "            data_traj = pd.read_excel(folder + '/' + entry_list[j],\n",
    "                                      sheet_name='Coords')\n",
    "            headers = list(data_traj.columns)\n",
    "            X_names = []\n",
    "            Y_names = []\n",
    "            for k in range(len(headers)):\n",
    "                if not (name_curr=='all_names'):\n",
    "                   try: \n",
    "                    if (('Coords X' in headers[k])and(name_curr in data_traj[headers[k+3]][0])):\n",
    "                        X_names.append(headers[k])\n",
    "                        #print('trytraj',data_traj[headers[k+3]][0])\n",
    "                    if (('Coords Y' in headers[k])and(name_curr in data_traj[headers[k+2]][0])):\n",
    "                        #print('trytraj1',data_traj[headers[k+2]][0])\n",
    "                        Y_names.append(headers[k])\n",
    "                   except Exception as e:\n",
    "                    print(e)\n",
    "                else:\n",
    "                    if (('Coords X' in headers[k])):\n",
    "                        X_names.append(headers[k])\n",
    "                        #print('trytraj',data_traj[headers[k+3]][0])\n",
    "                    if (('Coords Y' in headers[k])):\n",
    "                        #print('trytraj1',data_traj[headers[k+2]][0])\n",
    "                        Y_names.append(headers[k])\n",
    "\n",
    "            # print(Y_names)\n",
    "            for k in range(len(X_names)):\n",
    "                traj_lens_tmp = []\n",
    "                X_list = data_traj[X_names[k]].tolist()\n",
    "                X_list = [x for x in X_list if str(x) != 'nan']\n",
    "                Y_list = data_traj[Y_names[k]].tolist()\n",
    "                Y_list = [x for x in Y_list if str(x) != 'nan']\n",
    "                for k_int in range(1, len(X_list)):\n",
    "                    dist = np.sqrt((X_list[k_int] - X_list[k_int - 1])**2 +\n",
    "                                   (Y_list[k_int] - Y_list[k_int - 1])**2)\n",
    "                    # dist = np.sqrt((data_traj[X_names[k]][l + 1] - data_traj[X_names[k]][l]) ** 2 +\n",
    "                    #                (data_traj[Y_names[k]][l + 1] - data_traj[Y_names[k]][l]) ** 2)\n",
    "\n",
    "                    traj_lens_tmp.append(dist)\n",
    "                traj_lens.append(np.sum(traj_lens_tmp))\n",
    "\n",
    "    return traj_lens\n",
    "all_leuco_names = all_names(folder, filename, 1) \n",
    "\n",
    "print(all_leuco_names)\n",
    "dict_trajs = {}\n",
    "dict_velocities = {}\n",
    "for unique_names in all_leuco_names: \n",
    "    dict_trajs[unique_names] = []\n",
    "    dict_velocities[unique_names] = []\n",
    "for unique_names in all_leuco_names:    \n",
    "    trajectories = traj(folder, filename, 1, unique_names) # Траектории всех нейтрофилов, которые были на наших полях\n",
    "    print('Traj',trajectories)\n",
    "    for i in trajectories:\n",
    "        dict_trajs[unique_names].append(i)        \n",
    "raw_files = get_files(folder, filename)\n",
    "import re\n",
    "\n",
    "thrombus_area_300 = []\n",
    "thrombus_area_600 = []\n",
    "velocities = []\n",
    "\n",
    "for i in range (len(raw_files)):\n",
    "    pd_import = pd.read_excel(folder + '/' + raw_files[i], sheet_name='Mean values')\n",
    "\n",
    "    thrombus_area_300.append(pd_import['Unnamed: 0'][1] * 100)\n",
    "    thrombus_area_600.append(pd_import['Unnamed: 1'][1] * 100)\n",
    "    columns = list(pd_import.columns)\n",
    "    for unique_names in all_leuco_names: \n",
    "    \n",
    "    #     print(raw_files[i])\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    #     print(columns)\n",
    "        headers = list(pd_import.columns)\n",
    "        #print(unique_names)\n",
    "        for k in range(len(headers)-1):\n",
    "            print(pd_import[headers[k+1]][0])\n",
    "            try:\n",
    "                if not (unique_names=='all_names'):\n",
    "                    if ((re.search('eloc',headers[k]))and(re.search(unique_names,pd_import[headers[k+1]][0]))):\n",
    "                        #print('success', unique_names)\n",
    "                        dict_velocities[unique_names].append(pd_import[headers[k]][0])\n",
    "                else:\n",
    "                    print(headers[k])\n",
    "                    if ((re.search('eloc',headers[k]))):\n",
    "                        #print('success', unique_names)\n",
    "                        dict_velocities[unique_names].append(pd_import[headers[k]][0])\n",
    "            except:\n",
    "                pass\n",
    "        #print(dict_velocities[unique_names])\n",
    "        dict_velocities[unique_names] = [x for x in dict_velocities[unique_names] if str(x) != 'nan']\n",
    "\n",
    "\n",
    "        velocities_fast = []\n",
    "        trajectories_fast = []\n",
    "        for i in range(len(dict_velocities[unique_names])):\n",
    "\n",
    "            if dict_velocities[unique_names][i] > 0.045:\n",
    "                velocities_fast.append(dict_velocities[unique_names][i])\n",
    "                trajectories_fast.append(dict_trajs[unique_names][i])\n",
    "\n",
    "        out_list = [thrombus_area_300, thrombus_area_600, dict_velocities[unique_names], dict_trajs[unique_names], velocities_fast, trajectories_fast]\n",
    "\n",
    "\n",
    "        data_out = pd.DataFrame.from_records(out_list).transpose()\n",
    "\n",
    "        data_out.columns = ['300 s', '600 s', 'Velocities', 'Trajectories', 'Velocities > 0.045', 'Trajectories > 0.045']\n",
    "        #print(data_out)\n",
    "        data_out.to_excel(folder + '/' + filename + str(unique_names)+ '_fin.xlsx', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_leuco_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\Downloads/ulyana_002all_names_fin.xlsx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Julia\\\\Downloads/ulyana_002all_names_fin.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ef2d67cb5c2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#     print(file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0moutput_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-ef2d67cb5c2d>\u001b[0m in \u001b[0;36moutput_generator\u001b[1;34m(folder, filename)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'all_names_fin.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'all_names_fin.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmean_thrombus_300\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'300 s'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Julia\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Julia\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Julia\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[1;32mC:\\Users\\Julia\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Julia\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mfile_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;31m# We have to let unknown file formats pass through here, as some ancient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36minspect_format\u001b[1;34m(path, content)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Julia\\\\Downloads/ulyana_002all_names_fin.xlsx'"
     ]
    }
   ],
   "source": [
    "# Окошко, которое генерирует заключение\n",
    "\n",
    "def output_generator(folder, filename):\n",
    "    print(folder + '/' + filename + 'all_names_fin.xlsx')\n",
    "    \n",
    "    file = pd.read_excel(folder + '/' + filename + 'all_names_fin.xlsx')\n",
    "    \n",
    "    mean_thrombus_300 = np.mean(file['300 s'].tolist())\n",
    "    mean_thrombus_300_SD = np.std(file['300 s'].tolist())\n",
    "    \n",
    "    mean_thrombus_600 = np.mean(file['600 s'].tolist())\n",
    "    mean_thrombus_600_SD = np.std(file['600 s'].tolist())\n",
    "    \n",
    "    velocities_all = np.mean(file['Velocities'].tolist())\n",
    "    velocities_all_SD = np.std(file['Velocities'].tolist())\n",
    "    \n",
    "    trajectories_all = np.mean(file['Trajectories'].tolist())\n",
    "    trajectories_all_SD = np.std(file['Trajectories'].tolist())\n",
    "    \n",
    "    velocities_fast = np.mean(file['Velocities > 0.045'].dropna().tolist())\n",
    "    velocities_fast_SD = np.std(file['Velocities > 0.045'].dropna().tolist())\n",
    "    \n",
    "    trajectories_fast_all = np.mean(file['Trajectories > 0.045'].dropna().tolist())\n",
    "    trajectories_fast_all_SD = np.std(file['Trajectories > 0.045'].dropna().tolist())\n",
    "    \n",
    "    slow_number = 100 - len(file['Velocities > 0.045'].dropna().tolist()) * 100 / len(file['Velocities'].dropna().tolist())\n",
    "    \n",
    "    output = [mean_thrombus_300, mean_thrombus_300_SD, \n",
    "              mean_thrombus_600, mean_thrombus_600_SD,\n",
    "              velocities_all, velocities_all_SD, \n",
    "              trajectories_all, trajectories_all_SD, \n",
    "              velocities_fast, velocities_fast_SD, \n",
    "              trajectories_fast_all, trajectories_fast_all_SD, \n",
    "              slow_number]\n",
    "    \n",
    "    data_out = pd.DataFrame(output).transpose()\n",
    "    \n",
    "    data_out.columns = ['Thrombi, 300 s', 'Thrombi, 300 s| SD', \n",
    "                        'Thrombi, 600 s', 'Thrombi, 600 s| SD', \n",
    "                        'Velocities All', 'Velocities All | SD', \n",
    "                        'Trajectories All', 'Trajectories All | SD', \n",
    "                        'Velocities Fast', 'Velocities Fast | SD', \n",
    "                        'Trajectories Fast', 'Trajectories Fast | SD', 'Slow %']\n",
    "    \n",
    "    data_out.to_excel(folder + '/' + filename + '_conclusions.xlsx', index = None)\n",
    "    \n",
    "#     print(file)\n",
    "    \n",
    "output_generator(folder, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init_delay = 180\n",
    "#время тупежа\n",
    "patient_name = 'obydenny'\n",
    "\n",
    "folder_video = r'C:\\Users\\Julia\\Desktop\\Нейтрофильный тест\\Пении-обработка\\11112021\\11112021\\penia'\n",
    "\n",
    "#задержка начала с'емки\n",
    "def saveclots(init_delay,first_clot_time, folder):\n",
    "    datetime_filenames = {}\n",
    "    sec_difference_filenames = {}\n",
    "\n",
    "    all_files_nd2 = get_files_ND2(folder)\n",
    "\n",
    "\n",
    "    for all_files in all_files_nd2:\n",
    "        date_init = GetFilmingInitTime(folder+'/'+all_files)\n",
    "        datetime_filenames[all_files] = date_init\n",
    "\n",
    "\n",
    "    date_init = datetime_filenames[min(datetime_filenames, key=datetime_filenames.get)]\n",
    "\n",
    "\n",
    "    for all_files in all_files_nd2:\n",
    "        sec_difference_filenames[all_files] = (datetime_filenames[all_files]-date_init).total_seconds()+init_delay \n",
    "\n",
    "    sec_from_beginning_filenames ={}\n",
    "    sec_from_beginning_all = np.zeros(1)\n",
    "    for all_files in all_files_nd2:\n",
    "        times_curr = getND2timeframes(None,folder+'/'+all_files)+sec_difference_filenames[all_files]\n",
    "        sec_from_beginning_filenames[all_files] = times_curr\n",
    "        sec_from_beginning_all=np.concatenate((sec_from_beginning_all,times_curr))\n",
    "    sec_from_beginning_all = sec_from_beginning_all.tolist()    \n",
    "\n",
    "\n",
    "    first = sec_from_beginning_all.index(min(sec_from_beginning_all, key=lambda x: abs(x - first_clot_time)))    \n",
    "    filename_first = ''\n",
    "    closest_sec = sec_from_beginning_all[first]\n",
    "    for all_files in all_files_nd2:\n",
    "        if closest_sec in sec_from_beginning_filenames[all_files]:\n",
    "            filename_first = all_files\n",
    "            first_time_index = sec_from_beginning_filenames[all_files].tolist().index(closest_sec)\n",
    "            print (sec_from_beginning_filenames[all_files][first_time_index], sec_from_beginning_filenames[all_files].tolist().index(closest_sec))\n",
    "\n",
    "    frames_set_time = pims_nd2.ND2_Reader(folder+'/'+filename_first)\n",
    "    frames_set_time.default_coords['c'] = 1\n",
    "    ar = np.array(frames_set_time[first_time_index])\n",
    "    print(np.shape(ar))\n",
    "    import imageio\n",
    "    imageio.imwrite(folder+'/'+patient_name+str(first_clot_time)+'.tiff', ar)\n",
    "saveclots(init_delay,300, folder_video)\n",
    "saveclots(init_delay,600, folder_video)\n",
    "saveclots(init_delay,1500, folder_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from operator import itemgetter\n",
    "def get_files(path,printnames = False):\n",
    "\n",
    "    listOfFiles = os.listdir(path)\n",
    "    pattern = 'Segmentation'\n",
    "    \n",
    "    i = 0\n",
    "    filenames = {}\n",
    "    for entry in listOfFiles:\n",
    "        if pattern in entry:\n",
    "            \n",
    "            nametime = re.split('-',entry)[0]   \n",
    "            #patient_name = 'pi3k'\n",
    "            patient_name = re.sub(r'[0-9]+', '', nametime)\n",
    "            #patient_name = 'tesakov'\n",
    "            filenames[patient_name] = []\n",
    "    for entry in listOfFiles:\n",
    "        if pattern in entry:\n",
    "            \n",
    "            nametime = re.split('-',entry)[0]\n",
    "            image = imageio.imread(path+'/'+entry)\n",
    "            per_cent = len(image[image==2])/np.shape(image)[0]/np.shape(image)[1]\n",
    "            #print(per_cent)\n",
    "            patient_name = re.sub(r'[0-9]+', '', nametime)\n",
    "            \n",
    "            patient_time = int(re.sub(patient_name,'',nametime))\n",
    "            #patient_name = 'tesakov'\n",
    "            filenames[patient_name].append([patient_time,per_cent])         \n",
    "    #print(nametime)\n",
    "    \n",
    "\n",
    "    for keys in filenames:\n",
    "        filenames[keys]=(sorted(filenames[keys], key=itemgetter(0)))\n",
    "    print(filenames)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "folder = r'C:\\Users\\Julia\\Desktop\\Нейтрофильный тест\\Пении-обработка\\11112021\\11112021\\penia'\n",
    "\n",
    "filenames = get_files(folder)\n",
    "\n",
    "print(filenames)\n",
    "    \n",
    "    \n",
    "    \n",
    "#get_all_names = np.unique()\n",
    "\n",
    "import xlwt\n",
    "ex = xlwt.Workbook()\n",
    "squares = ex.add_sheet('ClotSquares', cell_overwrite_ok=True)\n",
    "                        \n",
    "i = 0                        \n",
    "for entries in filenames:\n",
    "            i+=1\n",
    "            squares.write(1,i, entries)\n",
    "            squares.write(2,i, filenames[entries][0][1])\n",
    "            squares.write(3,i, filenames[entries][1][1])\n",
    "            if not (entries=='platonov'):\n",
    "                squares.write(4,i, filenames[entries][2][1])\n",
    "  \n",
    "ex.save('fin.xls')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
